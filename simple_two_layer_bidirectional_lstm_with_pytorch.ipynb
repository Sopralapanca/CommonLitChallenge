{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bf1c614c3ca047fa9e1ca6947affe460": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_36eb0556acca4929acf3e6d4f157ce45",
              "IPY_MODEL_71b11561b39245839be936bb00301cbe",
              "IPY_MODEL_6d304e5e280144fdb06aaa1de4d0b324"
            ],
            "layout": "IPY_MODEL_a3cf7f64f0fd4a53876e3490b5c0c442"
          }
        },
        "36eb0556acca4929acf3e6d4f157ce45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_49587c71d3bf43cc8ce18af0cab46ab1",
            "placeholder": "​",
            "style": "IPY_MODEL_b305cda7e3ae429dae667545fb13cef3",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "71b11561b39245839be936bb00301cbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_218ea82d6d7344c7a12e05f5106e260c",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a66508ddeedf4cf0a6735503d249994b",
            "value": 213450
          }
        },
        "6d304e5e280144fdb06aaa1de4d0b324": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0548d23b2ec743d5ab419ce6a6053e56",
            "placeholder": "​",
            "style": "IPY_MODEL_558d43d062204341b1b3c3c3f6b6a062",
            "value": " 213k/213k [00:00&lt;00:00, 4.44MB/s]"
          }
        },
        "a3cf7f64f0fd4a53876e3490b5c0c442": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49587c71d3bf43cc8ce18af0cab46ab1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b305cda7e3ae429dae667545fb13cef3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "218ea82d6d7344c7a12e05f5106e260c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a66508ddeedf4cf0a6735503d249994b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0548d23b2ec743d5ab419ce6a6053e56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "558d43d062204341b1b3c3c3f6b6a062": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "072dcca6e6474906923eda8e40709732": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05a80f4fdff14797b50e760a9b415d04",
              "IPY_MODEL_c875b15bc0174cdf9da16cf1fb54ba29",
              "IPY_MODEL_bb683ad3a5b1467b8c5267bb817759e9"
            ],
            "layout": "IPY_MODEL_bc34ac5d97934909a6d748c8fba0e01c"
          }
        },
        "05a80f4fdff14797b50e760a9b415d04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ac078177f0940458e0c7719a9272615",
            "placeholder": "​",
            "style": "IPY_MODEL_d3700ed59bf84cdf86c65f0b8287154b",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "c875b15bc0174cdf9da16cf1fb54ba29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8415392c789043fb823dcbfe714aae41",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_96c10a77c0824a1a9be9db1743dbe33a",
            "value": 29
          }
        },
        "bb683ad3a5b1467b8c5267bb817759e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_491221b592b6402d9bbd6b7c1f773e96",
            "placeholder": "​",
            "style": "IPY_MODEL_cb3e5dae8eb3460a99c12088ba44fce6",
            "value": " 29.0/29.0 [00:00&lt;00:00, 350B/s]"
          }
        },
        "bc34ac5d97934909a6d748c8fba0e01c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ac078177f0940458e0c7719a9272615": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3700ed59bf84cdf86c65f0b8287154b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8415392c789043fb823dcbfe714aae41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96c10a77c0824a1a9be9db1743dbe33a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "491221b592b6402d9bbd6b7c1f773e96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb3e5dae8eb3460a99c12088ba44fce6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd68b4318d094cbf89254cccbe19a8f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_93ce4b472ed04237b31db6f4d998bd41",
              "IPY_MODEL_7fa655017baf4e06ac132e6c9623d9fe",
              "IPY_MODEL_300663ce932c494497a04d81c6fe272c"
            ],
            "layout": "IPY_MODEL_e45efb06e9a449078f97ef66283b0e33"
          }
        },
        "93ce4b472ed04237b31db6f4d998bd41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0307e187bda14d3a8f23c904d82f4d60",
            "placeholder": "​",
            "style": "IPY_MODEL_b6a2232563184254a4eaf6563471a097",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "7fa655017baf4e06ac132e6c9623d9fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fbf9cedd69c488abbd795a06de42e66",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b74fa878c1484829980defb4ac6cc506",
            "value": 570
          }
        },
        "300663ce932c494497a04d81c6fe272c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6461879648894280b91cd8593ef10205",
            "placeholder": "​",
            "style": "IPY_MODEL_efe8b2fd72bb45c9bf8328ea7d161f91",
            "value": " 570/570 [00:00&lt;00:00, 11.8kB/s]"
          }
        },
        "e45efb06e9a449078f97ef66283b0e33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0307e187bda14d3a8f23c904d82f4d60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6a2232563184254a4eaf6563471a097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fbf9cedd69c488abbd795a06de42e66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b74fa878c1484829980defb4ac6cc506": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6461879648894280b91cd8593ef10205": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efe8b2fd72bb45c9bf8328ea7d161f91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sopralapanca/CommonLitChallenge/blob/Sarde/simple_two_layer_bidirectional_lstm_with_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple two-layer bidirectional LSTM with Pytorch"
      ],
      "metadata": {
        "id": "kosQtmv9dkxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOVJtGeZKtGl",
        "outputId": "5adec77e-536e-49da-efb7-5af2edb1ef86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.32.1-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.32.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import copy\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import KFold\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from spacy.lang.en import English\n",
        "import string\n",
        "import spacy\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertPreTrainedModel, BertModel\n",
        "from transformers import AutoConfig, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoModelForSequenceClassification,AutoTokenizer\n",
        "\n",
        "from torch import nn\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from transformers import DebertaModel\n",
        "from transformers import DebertaPreTrainedModel\n",
        "from tqdm import tqdm, trange\n",
        "import os\n",
        "import gc\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import torch.nn.functional as F\n",
        "import torchtext\n",
        "import nltk\n",
        "import time\n",
        "from datetime import timedelta\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from keras.utils.data_utils import GeneratorEnqueuer  # We only want this for multithreaded\n",
        "\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pack_padded_sequence\n",
        "from torch import Tensor"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "YPNYAkzEdkxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define hyperparameters"
      ],
      "metadata": {
        "id": "vIsO947Mdkxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 250\n",
        "lr = 0.01\n",
        "n_folds = 5\n",
        "lstm_input_size = 1\n",
        "hidden_state_size = 30\n",
        "batch_size = 30\n",
        "num_sequence_layers = 2\n",
        "output_dim = 11\n",
        "num_time_steps = 4000\n",
        "rnn_type = 'LSTM'"
      ],
      "metadata": {
        "trusted": true,
        "id": "hG6CEunPdkxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define model"
      ],
      "metadata": {
        "id": "TecTr512dkxz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Bi_RNN(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, hidden_dim, batch_size, output_dim=11, num_layers=2, rnn_type='LSTM'):\n",
        "        super(Bi_RNN, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.batch_size = batch_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        #Define the initial linear hidden layer\n",
        "        self.init_linear = nn.Linear(self.input_dim, self.input_dim)\n",
        "\n",
        "        # Define the LSTM layer\n",
        "        self.lstm = eval('nn.' + rnn_type)(self.input_dim, self.hidden_dim, self.num_layers, batch_first=True, bidirectional=True)\n",
        "\n",
        "        # Define the output layer\n",
        "        self.linear = nn.Linear(self.hidden_dim * 2, output_dim)\n",
        "\n",
        "    def init_hidden(self):\n",
        "        # This is what we'll initialise our hidden state as\n",
        "        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
        "                torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))\n",
        "\n",
        "    def forward(self, input):\n",
        "        #Forward pass through initial hidden layer\n",
        "        linear_input = self.init_linear(input)\n",
        "\n",
        "        # Forward pass through LSTM layer\n",
        "        # shape of lstm_out: [batch_size, input_size ,hidden_dim]\n",
        "        # shape of self.hidden: (a, b), where a and b both\n",
        "        # have shape (batch_size, num_layers, hidden_dim).\n",
        "        lstm_out, self.hidden = self.lstm(linear_input)\n",
        "\n",
        "        # Can pass on the entirety of lstm_out to the next layer if it is a seq2seq prediction\n",
        "        y_pred = self.linear(lstm_out)\n",
        "        return y_pred"
      ],
      "metadata": {
        "trusted": true,
        "id": "nn0LG25Ddkx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define data loaders"
      ],
      "metadata": {
        "id": "7WNc1KiAdkx0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CommonLitDataset(Dataset):\n",
        "    #TODO: aggiungere max len specifica per tutti e 3 i campi\n",
        "    def __init__(self, data, maxlen, tokenizer, input_cols, target_cols, split=True, padding=True):\n",
        "        #Store the contents of the file in a pandas dataframe\n",
        "        self.df = data.reset_index()\n",
        "        #Initialize the tokenizer for the desired transformer model\n",
        "        self.tokenizer = tokenizer\n",
        "        #Maximum length of the tokens list to keep all the sequences of fixed size\n",
        "        self.maxlen = maxlen\n",
        "        #list of input columns\n",
        "        self.input_cols = input_cols\n",
        "        #list of target columns\n",
        "        self.target_cols = target_cols\n",
        "        self.prompt_text=[]\n",
        "        self.prompt_question=[]\n",
        "        self.summary=[]\n",
        "        self.split=split\n",
        "        self.padding=padding\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.df.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        #Select the sentence and label at the specified index in the data frame\n",
        "        prompt_text_tokens=[]\n",
        "        prompt_question_tokens=[]\n",
        "        summary_tokens=[]\n",
        "        #[\"text\",\"prompt_question\",\"prompt_text\"]\n",
        "\n",
        "        if(self.split==True):\n",
        "            prompt_text_tokens=['[CLS]'] + self.tokenizer.tokenize(self.df.loc[index, self.input_cols[2]])\n",
        "            prompt_question_tokens=['[CLS]'] + self.tokenizer.tokenize(self.df.loc[index, self.input_cols[1]])\n",
        "            summary_tokens=['[CLS]'] + self.tokenizer.tokenize(self.df.loc[index, self.input_cols[0]])\n",
        "            print(\"Length tokens= \", len(prompt_text_tokens),\", \", len(prompt_question_tokens),\", \", len(summary_tokens))\n",
        "            if len(prompt_text_tokens) < self.maxlen:\n",
        "                if self.padding:\n",
        "                    prompt_text_tokens = prompt_text_tokens + ['[PAD]' for _ in range(self.maxlen - len(prompt_text_tokens))]+ ['[SEP]']\n",
        "                else: prompt_text_tokens = prompt_text_tokens + ['[SEP]']\n",
        "            else:\n",
        "                print(\"Too long string\")\n",
        "                prompt_text_tokens = prompt_text_tokens[:self.maxlen-1] + ['[SEP]']\n",
        "            if len(prompt_question_tokens) < self.maxlen:\n",
        "                if self.padding:\n",
        "                    prompt_question_tokens = prompt_question_tokens + ['[PAD]' for _ in range(self.maxlen - len(prompt_question_tokens))]+ ['[SEP]']\n",
        "                else: prompt_question_tokens = prompt_question_tokens + ['[SEP]']\n",
        "            else:\n",
        "                print(\"Too long string\")\n",
        "                prompt_question_tokens = prompt_question_tokens[:self.maxlen-1] + ['[SEP]']\n",
        "            if len(summary_tokens) < self.maxlen:\n",
        "                if self.padding:\n",
        "                    summary_tokens = summary_tokens + ['[PAD]' for _ in range(self.maxlen - len(summary_tokens))]+ ['[SEP]']\n",
        "                else: summary_tokens = summary_tokens + ['[SEP]']\n",
        "            else:\n",
        "                print(\"Too long string\")\n",
        "                summary_tokens = summary_tokens[:self.maxlen-1] + ['[SEP]']\n",
        "\n",
        "            #Obtain the indices of the tokens in the BERT Vocabulary\n",
        "            prompt_text_input_ids = self.tokenizer.convert_tokens_to_ids(prompt_text_tokens)\n",
        "            prompt_question_tokens_input_ids = self.tokenizer.convert_tokens_to_ids(prompt_question_tokens)\n",
        "            summary_tokens_input_ids = self.tokenizer.convert_tokens_to_ids(summary_tokens)\n",
        "\n",
        "            prompt_text_input_ids = torch.tensor(prompt_text_input_ids)\n",
        "            prompt_question_tokens_input_ids = torch.tensor(prompt_question_tokens_input_ids)\n",
        "            summary_tokens_input_ids = torch.tensor(summary_tokens_input_ids)\n",
        "            input_ids=[prompt_text_input_ids, prompt_question_tokens_input_ids, summary_tokens_input_ids]\n",
        "            input_length=len(input_ids)\n",
        "\n",
        "        else:\n",
        "            #Select the sentence and label at the specified index in the data frame\n",
        "            tokens=[]\n",
        "            for col in self.input_cols:\n",
        "              temp_tokens = self.tokenizer.tokenize(self.df.loc[index, col])\n",
        "              tokens = tokens + temp_tokens + ['[SEP]']\n",
        "            print(\"Length Token\")\n",
        "            print(len(tokens))\n",
        "            #Preprocess the text to be suitable for the transformer\n",
        "            tokens = ['[CLS]'] + tokens\n",
        "            print(\"Length tokens= \", len(tokens))\n",
        "            if len(tokens) < self.maxlen:\n",
        "                if self.padding:\n",
        "                  input_length=len(tokens)\n",
        "                  tokens = tokens + ['[PAD]' for _ in range(self.maxlen - len(tokens))]\n",
        "            else:\n",
        "                print(\"Too long string\")\n",
        "                tokens = tokens[:self.maxlen-1]\n",
        "\n",
        "            #Obtain the indices of the tokens in the BERT Vocabulary\n",
        "            input_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
        "            input_ids = torch.tensor(input_ids)\n",
        "        try:\n",
        "            target = self.df.loc[index, self.target_cols]\n",
        "        except Exception as e:\n",
        "            raise e\n",
        "        target = torch.tensor(target, dtype=torch.float32)\n",
        "        return input_ids, input_length, target"
      ],
      "metadata": {
        "id": "31e7wx19lo8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.getcwd())\n",
        "summaries_train_path = \"https://raw.githubusercontent.com/Sopralapanca/CommonLitChallenge/main/data/summaries_train.csv\"\n",
        "prompt_train_path = \"https://raw.githubusercontent.com/Sopralapanca/CommonLitChallenge/main/data/prompts_train.csv\"\n",
        "\n",
        "summaries_test_path = \"https://raw.githubusercontent.com/Sopralapanca/CommonLitChallenge/main/data/summaries_test.csv\"\n",
        "prompt_test_path = \"https://raw.githubusercontent.com/Sopralapanca/CommonLitChallenge/main/data/prompts_test.csv\"\n",
        "\n",
        "train_data = pd.read_csv(summaries_train_path, sep=',', index_col=0)\n",
        "prompt_data = pd.read_csv(prompt_train_path, sep=',', index_col=0)"
      ],
      "metadata": {
        "id": "INFIUJyImmqO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1af8c9f-ee35-46e9-a48d-3e4b57d01da0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = train_data.merge(prompt_data, on='prompt_id')"
      ],
      "metadata": {
        "id": "i1tlhjStMaYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 874
        },
        "id": "kr5mf4tMUAOF",
        "outputId": "7b6199c8-0507-43dc-fffc-9fab6898c1dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     prompt_id                                               text   content  \\\n",
              "0       814d6b  The third wave was an experimentto see how peo...  0.205683   \n",
              "1       814d6b  The Third Wave developed  rapidly because the ...  3.272894   \n",
              "2       814d6b  The third wave only started as an experiment w...  0.205683   \n",
              "3       814d6b  The experimen was orginally about how even whe...  0.567975   \n",
              "4       814d6b  The third wave developed so quickly due to the... -0.910596   \n",
              "...        ...                                                ...       ...   \n",
              "7160    39c16e  It has to be made on a complex storyline, with... -0.981265   \n",
              "7161    39c16e  Aristotle descirbes an ideal tradgedy as being... -0.511077   \n",
              "7162    39c16e  A tragedy should have a complex plan not a sim... -0.834946   \n",
              "7163    39c16e  Aristotle believed that the ideal tradegy shou... -0.157460   \n",
              "7164    39c16e  An ideal tragety has three elements that make ... -0.393310   \n",
              "\n",
              "       wording                                    prompt_question  \\\n",
              "0     0.380538  Summarize how the Third Wave developed over su...   \n",
              "1     3.219757  Summarize how the Third Wave developed over su...   \n",
              "2     0.380538  Summarize how the Third Wave developed over su...   \n",
              "3     0.969062  Summarize how the Third Wave developed over su...   \n",
              "4    -0.081769  Summarize how the Third Wave developed over su...   \n",
              "...        ...                                                ...   \n",
              "7160 -1.548900  Summarize at least 3 elements of an ideal trag...   \n",
              "7161 -1.589115  Summarize at least 3 elements of an ideal trag...   \n",
              "7162 -0.593749  Summarize at least 3 elements of an ideal trag...   \n",
              "7163 -0.165811  Summarize at least 3 elements of an ideal trag...   \n",
              "7164  0.627128  Summarize at least 3 elements of an ideal trag...   \n",
              "\n",
              "        prompt_title                                        prompt_text  \n",
              "0     The Third Wave  Background \\nThe Third Wave experiment took pl...  \n",
              "1     The Third Wave  Background \\nThe Third Wave experiment took pl...  \n",
              "2     The Third Wave  Background \\nThe Third Wave experiment took pl...  \n",
              "3     The Third Wave  Background \\nThe Third Wave experiment took pl...  \n",
              "4     The Third Wave  Background \\nThe Third Wave experiment took pl...  \n",
              "...              ...                                                ...  \n",
              "7160      On Tragedy  Chapter 13 \\nAs the sequel to what has already...  \n",
              "7161      On Tragedy  Chapter 13 \\nAs the sequel to what has already...  \n",
              "7162      On Tragedy  Chapter 13 \\nAs the sequel to what has already...  \n",
              "7163      On Tragedy  Chapter 13 \\nAs the sequel to what has already...  \n",
              "7164      On Tragedy  Chapter 13 \\nAs the sequel to what has already...  \n",
              "\n",
              "[7165 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6611b9bd-d09b-44ed-86b2-9d118c8b8805\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt_id</th>\n",
              "      <th>text</th>\n",
              "      <th>content</th>\n",
              "      <th>wording</th>\n",
              "      <th>prompt_question</th>\n",
              "      <th>prompt_title</th>\n",
              "      <th>prompt_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>814d6b</td>\n",
              "      <td>The third wave was an experimentto see how peo...</td>\n",
              "      <td>0.205683</td>\n",
              "      <td>0.380538</td>\n",
              "      <td>Summarize how the Third Wave developed over su...</td>\n",
              "      <td>The Third Wave</td>\n",
              "      <td>Background \\nThe Third Wave experiment took pl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>814d6b</td>\n",
              "      <td>The Third Wave developed  rapidly because the ...</td>\n",
              "      <td>3.272894</td>\n",
              "      <td>3.219757</td>\n",
              "      <td>Summarize how the Third Wave developed over su...</td>\n",
              "      <td>The Third Wave</td>\n",
              "      <td>Background \\nThe Third Wave experiment took pl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>814d6b</td>\n",
              "      <td>The third wave only started as an experiment w...</td>\n",
              "      <td>0.205683</td>\n",
              "      <td>0.380538</td>\n",
              "      <td>Summarize how the Third Wave developed over su...</td>\n",
              "      <td>The Third Wave</td>\n",
              "      <td>Background \\nThe Third Wave experiment took pl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>814d6b</td>\n",
              "      <td>The experimen was orginally about how even whe...</td>\n",
              "      <td>0.567975</td>\n",
              "      <td>0.969062</td>\n",
              "      <td>Summarize how the Third Wave developed over su...</td>\n",
              "      <td>The Third Wave</td>\n",
              "      <td>Background \\nThe Third Wave experiment took pl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>814d6b</td>\n",
              "      <td>The third wave developed so quickly due to the...</td>\n",
              "      <td>-0.910596</td>\n",
              "      <td>-0.081769</td>\n",
              "      <td>Summarize how the Third Wave developed over su...</td>\n",
              "      <td>The Third Wave</td>\n",
              "      <td>Background \\nThe Third Wave experiment took pl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7160</th>\n",
              "      <td>39c16e</td>\n",
              "      <td>It has to be made on a complex storyline, with...</td>\n",
              "      <td>-0.981265</td>\n",
              "      <td>-1.548900</td>\n",
              "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
              "      <td>On Tragedy</td>\n",
              "      <td>Chapter 13 \\nAs the sequel to what has already...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7161</th>\n",
              "      <td>39c16e</td>\n",
              "      <td>Aristotle descirbes an ideal tradgedy as being...</td>\n",
              "      <td>-0.511077</td>\n",
              "      <td>-1.589115</td>\n",
              "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
              "      <td>On Tragedy</td>\n",
              "      <td>Chapter 13 \\nAs the sequel to what has already...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7162</th>\n",
              "      <td>39c16e</td>\n",
              "      <td>A tragedy should have a complex plan not a sim...</td>\n",
              "      <td>-0.834946</td>\n",
              "      <td>-0.593749</td>\n",
              "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
              "      <td>On Tragedy</td>\n",
              "      <td>Chapter 13 \\nAs the sequel to what has already...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7163</th>\n",
              "      <td>39c16e</td>\n",
              "      <td>Aristotle believed that the ideal tradegy shou...</td>\n",
              "      <td>-0.157460</td>\n",
              "      <td>-0.165811</td>\n",
              "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
              "      <td>On Tragedy</td>\n",
              "      <td>Chapter 13 \\nAs the sequel to what has already...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7164</th>\n",
              "      <td>39c16e</td>\n",
              "      <td>An ideal tragety has three elements that make ...</td>\n",
              "      <td>-0.393310</td>\n",
              "      <td>0.627128</td>\n",
              "      <td>Summarize at least 3 elements of an ideal trag...</td>\n",
              "      <td>On Tragedy</td>\n",
              "      <td>Chapter 13 \\nAs the sequel to what has already...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7165 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6611b9bd-d09b-44ed-86b2-9d118c8b8805')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6611b9bd-d09b-44ed-86b2-9d118c8b8805 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6611b9bd-d09b-44ed-86b2-9d118c8b8805');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6552ece9-f387-4379-b76a-eb05a42730c4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6552ece9-f387-4379-b76a-eb05a42730c4')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6552ece9-f387-4379-b76a-eb05a42730c4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data['prompt_text_length']= training_data['prompt_text'].str.len()\n",
        "training_data['prompt_question_length']=training_data['prompt_question'].str.len()\n",
        "training_data['student_summary_length']=training_data['text'].str.len()"
      ],
      "metadata": {
        "id": "aztQkXozTJxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(training_data,  test_size=0.2, shuffle=True)\n",
        "train, validation = train_test_split(train,  test_size=0.2, shuffle=True)"
      ],
      "metadata": {
        "id": "N-BZ7vfrMRpI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data.describe()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "BGzPWFGWUP36",
        "outputId": "7bae0c24-661e-4371-ea96-12920356c72f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           content      wording  prompt_text_length  prompt_question_length  \\\n",
              "count  7165.000000  7165.000000         7165.000000             7165.000000   \n",
              "mean     -0.014853    -0.063072         3875.733845              118.833775   \n",
              "std       1.043569     1.036048          784.383272               42.239220   \n",
              "min      -1.729859    -1.962614         3329.000000               77.000000   \n",
              "25%      -0.799545    -0.872720         3329.000000               77.000000   \n",
              "50%      -0.093814    -0.081769         3360.000000              104.000000   \n",
              "75%       0.499660     0.503833         5132.000000              184.000000   \n",
              "max       3.900326     4.310693         5132.000000              184.000000   \n",
              "\n",
              "       student_summary_length  \n",
              "count             7165.000000  \n",
              "mean               418.776971  \n",
              "std                307.833685  \n",
              "min                114.000000  \n",
              "25%                216.000000  \n",
              "50%                320.000000  \n",
              "75%                513.000000  \n",
              "max               3940.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-75d85e81-15e5-407d-b6ca-e5d145bfc71b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>wording</th>\n",
              "      <th>prompt_text_length</th>\n",
              "      <th>prompt_question_length</th>\n",
              "      <th>student_summary_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>7165.000000</td>\n",
              "      <td>7165.000000</td>\n",
              "      <td>7165.000000</td>\n",
              "      <td>7165.000000</td>\n",
              "      <td>7165.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-0.014853</td>\n",
              "      <td>-0.063072</td>\n",
              "      <td>3875.733845</td>\n",
              "      <td>118.833775</td>\n",
              "      <td>418.776971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.043569</td>\n",
              "      <td>1.036048</td>\n",
              "      <td>784.383272</td>\n",
              "      <td>42.239220</td>\n",
              "      <td>307.833685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-1.729859</td>\n",
              "      <td>-1.962614</td>\n",
              "      <td>3329.000000</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>114.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-0.799545</td>\n",
              "      <td>-0.872720</td>\n",
              "      <td>3329.000000</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>216.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-0.093814</td>\n",
              "      <td>-0.081769</td>\n",
              "      <td>3360.000000</td>\n",
              "      <td>104.000000</td>\n",
              "      <td>320.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.499660</td>\n",
              "      <td>0.503833</td>\n",
              "      <td>5132.000000</td>\n",
              "      <td>184.000000</td>\n",
              "      <td>513.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.900326</td>\n",
              "      <td>4.310693</td>\n",
              "      <td>5132.000000</td>\n",
              "      <td>184.000000</td>\n",
              "      <td>3940.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75d85e81-15e5-407d-b6ca-e5d145bfc71b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-75d85e81-15e5-407d-b6ca-e5d145bfc71b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-75d85e81-15e5-407d-b6ca-e5d145bfc71b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cc9e4868-89c7-4b20-99fa-f0278556da37\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cc9e4868-89c7-4b20-99fa-f0278556da37')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const charts = await google.colab.kernel.invokeFunction(\n",
              "          'suggestCharts', [key], {});\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cc9e4868-89c7-4b20-99fa-f0278556da37 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
      ],
      "metadata": {
        "id": "wo9sOAdlZgSt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "bf1c614c3ca047fa9e1ca6947affe460",
            "36eb0556acca4929acf3e6d4f157ce45",
            "71b11561b39245839be936bb00301cbe",
            "6d304e5e280144fdb06aaa1de4d0b324",
            "a3cf7f64f0fd4a53876e3490b5c0c442",
            "49587c71d3bf43cc8ce18af0cab46ab1",
            "b305cda7e3ae429dae667545fb13cef3",
            "218ea82d6d7344c7a12e05f5106e260c",
            "a66508ddeedf4cf0a6735503d249994b",
            "0548d23b2ec743d5ab419ce6a6053e56",
            "558d43d062204341b1b3c3c3f6b6a062",
            "072dcca6e6474906923eda8e40709732",
            "05a80f4fdff14797b50e760a9b415d04",
            "c875b15bc0174cdf9da16cf1fb54ba29",
            "bb683ad3a5b1467b8c5267bb817759e9",
            "bc34ac5d97934909a6d748c8fba0e01c",
            "9ac078177f0940458e0c7719a9272615",
            "d3700ed59bf84cdf86c65f0b8287154b",
            "8415392c789043fb823dcbfe714aae41",
            "96c10a77c0824a1a9be9db1743dbe33a",
            "491221b592b6402d9bbd6b7c1f773e96",
            "cb3e5dae8eb3460a99c12088ba44fce6",
            "cd68b4318d094cbf89254cccbe19a8f7",
            "93ce4b472ed04237b31db6f4d998bd41",
            "7fa655017baf4e06ac132e6c9623d9fe",
            "300663ce932c494497a04d81c6fe272c",
            "e45efb06e9a449078f97ef66283b0e33",
            "0307e187bda14d3a8f23c904d82f4d60",
            "b6a2232563184254a4eaf6563471a097",
            "6fbf9cedd69c488abbd795a06de42e66",
            "b74fa878c1484829980defb4ac6cc506",
            "6461879648894280b91cd8593ef10205",
            "efe8b2fd72bb45c9bf8328ea7d161f91"
          ]
        },
        "outputId": "022d2281-bd5b-42b2-a12e-b2f93fd5e8ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf1c614c3ca047fa9e1ca6947affe460"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "072dcca6e6474906923eda8e40709732"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd68b4318d094cbf89254cccbe19a8f7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN=2000\n",
        "BATCH_SIZE=10\n",
        "split=False\n",
        "padding= True\n",
        "input_cols=[\"text\",\"prompt_question\",\"prompt_text\"]\n",
        "target_cols=[\"content\", \"wording\"]\n",
        "train_set = CommonLitDataset(data=train, maxlen=MAX_LEN, tokenizer=tokenizer, input_cols=input_cols, target_cols=target_cols, split=split, padding=padding)\n",
        "valid_set = CommonLitDataset(data=validation, maxlen=MAX_LEN, tokenizer=tokenizer, input_cols=input_cols, target_cols=target_cols, split=split, padding=padding)\n",
        "test_set = CommonLitDataset(data=test, maxlen=MAX_LEN, tokenizer=tokenizer, input_cols=input_cols, target_cols=target_cols, split=split, padding=padding)\n",
        "\n",
        "train_loader = DataLoader(dataset=train_set, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n",
        "valid_loader = DataLoader(dataset=valid_set, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)\n",
        "test_loader = DataLoader(dataset=test_set, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)"
      ],
      "metadata": {
        "id": "VPAm8YYDmG-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = next(iter(train_loader))"
      ],
      "metadata": {
        "id": "2wLFymSWet8w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a31ab34-389f-429e-86c2-2e6390149f5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length Token\n",
            "814\n",
            "Length tokens=  815\n",
            "Length Token\n",
            "878\n",
            "Length tokens=  879\n",
            "Length Token\n",
            "1551\n",
            "Length tokens=  1552\n",
            "Length Token\n",
            "888\n",
            "Length tokens=  889\n",
            "Length Token\n",
            "811\n",
            "Length tokens=  812\n",
            "Length Token\n",
            "830\n",
            "Length tokens=  831\n",
            "Length Token\n",
            "737\n",
            "Length tokens=  738\n",
            "Length Token\n",
            "760\n",
            "Length tokens=  761\n",
            "Length Token\n",
            "785\n",
            "Length tokens=  786\n",
            "Length Token\n",
            "926\n",
            "Length tokens=  927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFJXojYMjhVy",
        "outputId": "5f297bae-7e16-40ef-e0af-99a4d3b9ff42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[ 101, 1109, 2890,  ...,    0,    0,    0],\n",
              "         [ 101, 1109, 1503,  ...,    0,    0,    0],\n",
              "         [ 101, 1370, 1122,  ...,    0,    0,    0],\n",
              "         ...,\n",
              "         [ 101, 1109, 7886,  ...,    0,    0,    0],\n",
              "         [ 101, 1247, 1301,  ...,    0,    0,    0],\n",
              "         [ 101, 1109, 2401,  ...,    0,    0,    0]]),\n",
              " tensor([ 815,  879, 1552,  889,  812,  831,  738,  761,  786,  927]),\n",
              " tensor([[-0.3238, -1.5855],\n",
              "         [ 3.0208,  2.4212],\n",
              "         [-0.3823, -1.7955],\n",
              "         [ 0.8937,  1.1725],\n",
              "         [ 0.7350, -0.0922],\n",
              "         [-0.0773,  0.4244],\n",
              "         [-1.0656, -0.2021],\n",
              "         [-0.1852,  1.0531],\n",
              "         [-0.9702, -0.4171],\n",
              "         [ 1.6588, -0.0931]])]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim1, hidden_dim2, output_dim, n_layers,\n",
        "                 bidirectional, dropout, pad_index):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx = pad_index)\n",
        "        self.lstm = nn.LSTM(embedding_dim,\n",
        "                            hidden_dim1,\n",
        "                            num_layers=n_layers,\n",
        "                            bidirectional=bidirectional,\n",
        "                            batch_first=True)\n",
        "        self.fc1 = nn.Linear(hidden_dim1 * 2, hidden_dim2)\n",
        "        self.fc2 = nn.Linear(hidden_dim2, output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, embedded, text_lengths):\n",
        "        packed_embedded = pack_padded_sequence(embedded, text_lengths, batch_first=True, enforce_sorted=False)\n",
        "\n",
        "        packed_output, (hidden, cell) = self.lstm(packed_embedded)\n",
        "        cat = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n",
        "        rel = self.relu(cat)\n",
        "        dense1 = self.fc1(rel)\n",
        "        drop = self.dropout(dense1)\n",
        "        preds = self.fc2(drop)\n",
        "        return preds"
      ],
      "metadata": {
        "id": "oVG2C0MgcZ_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, criterion, dataloader, device):\n",
        "    model.eval()\n",
        "    mean_acc, mean_loss, count = 0, 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for input_ids, attention_mask, target in (dataloader):\n",
        "\n",
        "            input_ids, attention_mask, target = input_ids.to(device), attention_mask.to(device), target.to(device)\n",
        "            output = model(input_ids, attention_mask)\n",
        "\n",
        "            mean_loss += criterion(output, target).item()\n",
        "            #mean_loss += get_rmse(output, target.type_as(output)).item()\n",
        "            count += 1\n",
        "\n",
        "    return mean_loss/count\n",
        "\n",
        "\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "def train(model, criterion, optimizer, train_loader, val_loader, epochs, device):\n",
        "    best_acc = 0\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for i, (input_ids, input_length, target) in enumerate(iterable=train_loader):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            input_ids, target = input_ids.to(device), target.to(device)\n",
        "\n",
        "            output = model(input_ids, input_length)\n",
        "\n",
        "            loss = criterion(output, target.type_as(output))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        tl = train_loss/len(train_loader)\n",
        "        val_loss = evaluate(model=model, criterion = criterion, dataloader=val_loader, device=device)\n",
        "        print(f\"Epoch {epoch} - Training Loss: {tl} Validation Loss: {val_loss}\")"
      ],
      "metadata": {
        "id": "RQB6shksx7wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RMSELoss(nn.Module):\n",
        "    def __init__(self, eps=1e-6):\n",
        "        super().__init__()\n",
        "        self.mse = nn.MSELoss()\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, yhat, y):\n",
        "        loss = torch.sqrt(self.mse(yhat, y) + self.eps)\n",
        "        return loss\n",
        "\n",
        "\n",
        "class MCRMSELoss(nn.Module):\n",
        "    def __init__(self, num_scored=2):\n",
        "        super().__init__()\n",
        "        self.rmse = RMSELoss()\n",
        "        self.num_scored = num_scored\n",
        "\n",
        "    def forward(self, yhat, y):\n",
        "        score = 0\n",
        "        for i in range(self.num_scored):\n",
        "            score += self.rmse(yhat[:, i], y[:, i]) / self.num_scored\n",
        "\n",
        "        return score"
      ],
      "metadata": {
        "id": "DQXKF79TjfAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 1e-3\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = LSTM(vocab_size=28996,embedding_dim=20, bidirectional=True,dropout=0.5,hidden_dim1=100, hidden_dim2=50,n_layers=2,output_dim=2,pad_index=1 )\n",
        "OPTIMIZER = optim.Adam(params=model.parameters(), lr=LR)\n",
        "EPOCHS = 5\n",
        "CRITERION = MCRMSELoss()\n",
        "train(model=model,\n",
        "      criterion=CRITERION,\n",
        "      optimizer=OPTIMIZER,\n",
        "      train_loader=train_loader,\n",
        "      val_loader=valid_loader,\n",
        "      epochs = EPOCHS,\n",
        "     device = device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 910
        },
        "id": "o9M_LpuLig5p",
        "outputId": "622afbd7-eceb-43ae-d725-de31bc0934ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length Token\n",
            "1450\n",
            "Length tokens=  1451\n",
            "Length Token\n",
            "797\n",
            "Length tokens=  798\n",
            "Length Token\n",
            "794\n",
            "Length tokens=  795\n",
            "Length Token\n",
            "1262\n",
            "Length tokens=  1263\n",
            "Length Token\n",
            "1285\n",
            "Length tokens=  1286\n",
            "Length Token\n",
            "913\n",
            "Length tokens=  914\n",
            "Length Token\n",
            "932\n",
            "Length tokens=  933\n",
            "Length Token\n",
            "1493\n",
            "Length tokens=  1494\n",
            "Length Token\n",
            "744\n",
            "Length tokens=  745\n",
            "Length Token\n",
            "823\n",
            "Length tokens=  824\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-55-36037681b15c>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mCRITERION\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMCRMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m train(model=model,\n\u001b[0m\u001b[1;32m      8\u001b[0m       \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCRITERION\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mOPTIMIZER\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-54-daa0eda7223c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer, train_loader, val_loader, epochs, device)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-fb68a191a5d8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, embedded, text_lengths)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mpacked_embedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menforce_sorted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mpacked_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_embedded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mcat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mrel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    808\u001b[0m             \u001b[0mhx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    728\u001b[0m                            \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                            ):\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m         self.check_hidden_size(hidden[0], self.get_expected_hidden_size(input, batch_sizes),\n\u001b[1;32m    732\u001b[0m                                'Expected hidden[0] size {}, got {}')\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mexpected_input_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_input_dim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m    215\u001b[0m                 'input must have {} dimensions, got {}'.format(\n\u001b[1;32m    216\u001b[0m                     expected_input_dim, input.dim()))\n",
            "\u001b[0;31mRuntimeError\u001b[0m: input must have 2 dimensions, got 1"
          ]
        }
      ]
    }
  ]
}